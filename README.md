# GANs

- DCGAN (Deep Convolutional Generative Adversarial Networks) was proposed in 2015 by Alec Radford, Luke Metz and Soumith Chintala. This model was one of the first to demonstrate that GANs could be used to generate realistic images, and it has been widely used as a starting point for other image generation models.

- StyleGAN (A Style-Based Generator Architecture for Generative Adversarial Networks) was proposed by NVIDIA researchers in 2018. StyleGAN is particularly good at generating high-resolution images of faces, and it has been used to create a number of well-known "deepfake" images.

- BigGAN, proposed in 2018, is a GAN architecture that uses very large (up to 512x512 pixels) images, and generates high-resolution images of high quality.

- PGGAN (Progressive Growing of GANs) proposed in 2017. In this model, the generator network starts by generating low-resolution images, and then gradually increases the resolution over time, allowing it to generate high-resolution images without needing a large amount of memory.

- CycleGAN proposed in 2017, it uses two GANs to translate an image from one domain to another domain. For example, it can be used to translate a photograph of a horse into a painting of a horse.
